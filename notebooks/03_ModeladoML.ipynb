{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842c6da2",
   "metadata": {},
   "source": [
    "<h1 style=\"background: linear-gradient(180deg,rgb(92, 0, 128) 0%,rgb(46, 0, 153) 75%, rgb(65, 0, 230) 100%); color: white; font-family: 'Raleway', sans-serif; padding: 10px 20px; border-radius: 10px; text-align: center; font-weight:500;\">\n",
    "Modelado con ML\n",
    "</h1>\n",
    "<br>\n",
    "\n",
    "**PRESENTA** Armando Islas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18977ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import time\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8faa65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se encuentran los archivos pkl\n",
    "DATA_DIR = \"../outputs/text-reps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e51fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos a utilizar\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=200),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier()\n",
    "}\n",
    "\n",
    "# Definir las métricas a calcular\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision_macro': make_scorer(precision_score, average='macro'),\n",
    "    'recall_macro': make_scorer(recall_score, average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e4d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar los datos\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = pickle.load(f)\n",
    "    \n",
    "    # Extraer X e y del diccionario\n",
    "    X = result['X']\n",
    "    y = result['y']\n",
    "    \n",
    "    # Podemos extraer la configuración para registro en MLflow\n",
    "    config = result['config']\n",
    "    \n",
    "    return X, y, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8add35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para aplicar LabelEncoder a las etiquetas\n",
    "def encode_labels(y):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    # Guardar el mapeo de clases para referencia\n",
    "    class_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "    return y_encoded, label_encoder, class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d1ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para aplicar oversampling\n",
    "def apply_oversampling(X, y):\n",
    "    oversample = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e690067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar modelos con validación cruzada\n",
    "def train_and_evaluate(X, y, model_name, model, dataset_name, config, class_mapping):\n",
    "    # Configurar la validación cruzada estratificada\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Iniciar MLflow run\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_{dataset_name}\"):\n",
    "        # Registrar el nombre del modelo y del dataset\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
    "        \n",
    "        # Registrar la configuración del dataset\n",
    "        mlflow.log_param(\"ngram_range\", str(config['ngram_range']))\n",
    "        mlflow.log_param(\"mode\", config['mode'])\n",
    "        mlflow.log_param(\"svd_components\", config['svd_components'])\n",
    "        \n",
    "        # Registrar el mapeo de clases\n",
    "        for original_class, encoded_value in class_mapping.items():\n",
    "            mlflow.log_param(f\"class_{encoded_value}\", original_class)\n",
    "        \n",
    "        # Medir el tiempo de ejecución\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Realizar validación cruzada con múltiples métricas\n",
    "        cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "        \n",
    "        # Calcular tiempo total\n",
    "        exec_time = time.time() - start_time\n",
    "        \n",
    "        # Registrar métricas promedio\n",
    "        for metric_name, metric_values in cv_results.items():\n",
    "            if metric_name.startswith('test_'):\n",
    "                # Solo registrar métricas de evaluación (no tiempos)\n",
    "                metric_avg = np.mean(metric_values)\n",
    "                mlflow.log_metric(metric_name.replace('test_', ''), metric_avg)\n",
    "        \n",
    "        # Registrar tiempo de ejecución\n",
    "        mlflow.log_metric(\"execution_time\", exec_time)\n",
    "        \n",
    "        # Devolver resultados para el dataframe final\n",
    "        return {\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'ngram_range': str(config['ngram_range']),\n",
    "            'mode': config['mode'],\n",
    "            'svd_components': config['svd_components'],\n",
    "            'num_classes': len(class_mapping),\n",
    "            'f1_macro': np.mean(cv_results['test_f1_macro']),\n",
    "            'accuracy': np.mean(cv_results['test_accuracy']),\n",
    "            'precision_macro': np.mean(cv_results['test_precision_macro']),\n",
    "            'recall_macro': np.mean(cv_results['test_recall_macro']),\n",
    "            'execution_time': exec_time\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9835ac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 27 archivos pkl para procesar.\n",
      "Procesando archivo 1/27: normalized_all_uni_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6686\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8953\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8808\n",
      "Procesando archivo 2/27: normalized_token_stop_lemma_uni_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6672\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8956\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8686\n",
      "Procesando archivo 3/27: normalized_token_stop_bi_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5480\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8778\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8374\n",
      "Procesando archivo 4/27: normalized_all_tri_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.4845\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8960\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8527\n",
      "Procesando archivo 5/27: normalized_all_uni_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6731\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8941\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8817\n",
      "Procesando archivo 6/27: normalized_token_stop_uni_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6870\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8981\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8830\n",
      "Procesando archivo 7/27: normalized_token_stop_lemma_bi_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5702\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8843\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8510\n",
      "Procesando archivo 8/27: normalized_token_stop_uni_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6792\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8961\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8765\n",
      "Procesando archivo 9/27: normalized_token_stop_lemma_uni_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6770\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8960\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8799\n",
      "Procesando archivo 10/27: normalized_all_bi_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5267\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8943\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8544\n",
      "Procesando archivo 11/27: normalized_token_stop_uni_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6748\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8968\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8755\n",
      "Procesando archivo 12/27: normalized_token_stop_lemma_uni_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6760\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8913\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8737\n",
      "Procesando archivo 13/27: normalized_token_stop_tri_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.4956\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8967\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8515\n",
      "Procesando archivo 14/27: normalized_all_bi_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5788\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.9023\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8728\n",
      "Procesando archivo 15/27: normalized_token_stop_tri_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.4669\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8933\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8417\n",
      "Procesando archivo 16/27: normalized_all_tri_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.4450\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8975\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8558\n",
      "Procesando archivo 17/27: normalized_token_stop_bi_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5436\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8726\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8451\n",
      "Procesando archivo 18/27: normalized_token_stop_tri_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5574\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.9071\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8520\n",
      "Procesando archivo 19/27: normalized_token_stop_bi_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5623\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8883\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8505\n",
      "Procesando archivo 20/27: normalized_token_stop_lemma_bi_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5808\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.9021\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8692\n",
      "Procesando archivo 21/27: normalized_all_uni_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(1, 1), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.6661\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8986\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8797\n",
      "Procesando archivo 22/27: normalized_all_bi_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5187\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8926\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8613\n",
      "Procesando archivo 23/27: normalized_token_stop_lemma_tri_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5596\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.9046\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8573\n",
      "Procesando archivo 24/27: normalized_token_stop_lemma_bi_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(2, 2), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5633\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8898\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8506\n",
      "Procesando archivo 25/27: normalized_all_tri_tfidf_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=tfidf, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.5594\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.9081\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8514\n",
      "Procesando archivo 26/27: normalized_token_stop_lemma_tri_freq_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=freq, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.4608\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8980\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8573\n",
      "Procesando archivo 27/27: normalized_token_stop_lemma_tri_binary_svd50.pkl\n",
      "  Clases originales: ['Clickbait' 'No']\n",
      "  Mapeo de clases: {'Clickbait': 0, 'No': 1}\n",
      "  Datos cargados, etiquetas codificadas y balanceadas. Shape: (4004, 50)\n",
      "  Configuración: n-grams=(3, 3), mode=binary, svd_components=50\n",
      "  Distribución de clases después de oversampling: [2002 2002]\n",
      "  Entrenando LogisticRegression...\n",
      "  LogisticRegression completado. F1-macro: 0.4826\n",
      "  Entrenando RandomForestClassifier...\n",
      "  RandomForestClassifier completado. F1-macro: 0.8955\n",
      "  Entrenando XGBClassifier...\n",
      "  XGBClassifier completado. F1-macro: 0.8588\n",
      "\n",
      "Top 10 mejores combinaciones (por F1-macro):\n",
      "                                        dataset                  model ngram_range   mode  svd_components  num_classes  f1_macro  accuracy  precision_macro  recall_macro  execution_time\n",
      "             normalized_all_tri_tfidf_svd50.pkl RandomForestClassifier      (3, 3)  tfidf              50            2  0.908096  0.908344         0.912439      0.908360        7.168672\n",
      "      normalized_token_stop_tri_tfidf_svd50.pkl RandomForestClassifier      (3, 3)  tfidf              50            2  0.907111  0.907346         0.911115      0.907358        7.346288\n",
      "normalized_token_stop_lemma_tri_tfidf_svd50.pkl RandomForestClassifier      (3, 3)  tfidf              50            2  0.904624  0.904846         0.908391      0.904860        7.780937\n",
      "              normalized_all_bi_tfidf_svd50.pkl RandomForestClassifier      (2, 2)  tfidf              50            2  0.902295  0.902351         0.903300      0.902358        7.907571\n",
      " normalized_token_stop_lemma_bi_tfidf_svd50.pkl RandomForestClassifier      (2, 2)  tfidf              50            2  0.902052  0.902100         0.902872      0.902110        7.311120\n",
      "            normalized_all_uni_binary_svd50.pkl RandomForestClassifier      (1, 1) binary              50            2  0.898575  0.898606         0.899122      0.898617        6.533892\n",
      "      normalized_token_stop_uni_tfidf_svd50.pkl RandomForestClassifier      (1, 1)  tfidf              50            2  0.898095  0.898105         0.898280      0.898114        6.412776\n",
      " normalized_token_stop_lemma_tri_freq_svd50.pkl RandomForestClassifier      (3, 3)   freq              50            2  0.897988  0.898102         0.899816      0.898110        6.226011\n",
      "              normalized_all_tri_freq_svd50.pkl RandomForestClassifier      (3, 3)   freq              50            2  0.897519  0.897605         0.898805      0.897614        6.130422\n",
      "     normalized_token_stop_uni_binary_svd50.pkl RandomForestClassifier      (1, 1) binary              50            2  0.896820  0.896855         0.897448      0.896870        6.747804\n",
      "\n",
      "Rendimiento promedio por tipo de modelo:\n",
      "model\n",
      "RandomForestClassifier    0.894924\n",
      "XGBClassifier             0.861851\n",
      "LogisticRegression        0.576781\n",
      "Name: f1_macro, dtype: float64\n",
      "\n",
      "Rendimiento promedio por n-gramas:\n",
      "ngram_range\n",
      "(1, 1)    0.815926\n",
      "(2, 2)    0.766255\n",
      "(3, 3)    0.751375\n",
      "Name: f1_macro, dtype: float64\n",
      "\n",
      "Rendimiento promedio por modo de vectorización:\n",
      "mode\n",
      "tfidf     0.790145\n",
      "binary    0.773652\n",
      "freq      0.769759\n",
      "Name: f1_macro, dtype: float64\n",
      "                                             dataset                   model  \\\n",
      "73                normalized_all_tri_tfidf_svd50.pkl  RandomForestClassifier   \n",
      "52         normalized_token_stop_tri_tfidf_svd50.pkl  RandomForestClassifier   \n",
      "67   normalized_token_stop_lemma_tri_tfidf_svd50.pkl  RandomForestClassifier   \n",
      "40                 normalized_all_bi_tfidf_svd50.pkl  RandomForestClassifier   \n",
      "58    normalized_token_stop_lemma_bi_tfidf_svd50.pkl  RandomForestClassifier   \n",
      "..                                               ...                     ...   \n",
      "9                normalized_all_tri_binary_svd50.pkl      LogisticRegression   \n",
      "78  normalized_token_stop_lemma_tri_binary_svd50.pkl      LogisticRegression   \n",
      "42          normalized_token_stop_tri_freq_svd50.pkl      LogisticRegression   \n",
      "75    normalized_token_stop_lemma_tri_freq_svd50.pkl      LogisticRegression   \n",
      "45                 normalized_all_tri_freq_svd50.pkl      LogisticRegression   \n",
      "\n",
      "   ngram_range    mode  svd_components  num_classes  f1_macro  accuracy  \\\n",
      "73      (3, 3)   tfidf              50            2  0.908096  0.908344   \n",
      "52      (3, 3)   tfidf              50            2  0.907111  0.907346   \n",
      "67      (3, 3)   tfidf              50            2  0.904624  0.904846   \n",
      "40      (2, 2)   tfidf              50            2  0.902295  0.902351   \n",
      "58      (2, 2)   tfidf              50            2  0.902052  0.902100   \n",
      "..         ...     ...             ...          ...       ...       ...   \n",
      "9       (3, 3)  binary              50            2  0.484504  0.525973   \n",
      "78      (3, 3)  binary              50            2  0.482638  0.536213   \n",
      "42      (3, 3)    freq              50            2  0.466881  0.516234   \n",
      "75      (3, 3)    freq              50            2  0.460795  0.511737   \n",
      "45      (3, 3)    freq              50            2  0.444997  0.504491   \n",
      "\n",
      "    precision_macro  recall_macro  execution_time  \n",
      "73         0.912439      0.908360        7.168672  \n",
      "52         0.911115      0.907358        7.346288  \n",
      "67         0.908391      0.904860        7.780937  \n",
      "40         0.903300      0.902358        7.907571  \n",
      "58         0.902872      0.902110        7.311120  \n",
      "..              ...           ...             ...  \n",
      "9          0.538498      0.526107        0.529087  \n",
      "78         0.561940      0.536223        0.679101  \n",
      "42         0.525030      0.516241        0.364233  \n",
      "75         0.518210      0.511741        0.462503  \n",
      "45         0.506128      0.504482        0.405938  \n",
      "\n",
      "[81 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar todos los resultados\n",
    "all_results = []\n",
    "\n",
    "# Obtener lista de archivos pkl\n",
    "pkl_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.pkl')]\n",
    "\n",
    "print(f\"Encontrados {len(pkl_files)} archivos pkl para procesar.\")\n",
    "\n",
    "# Procesar cada archivo\n",
    "for i, pkl_file in enumerate(pkl_files):\n",
    "    print(f\"Procesando archivo {i+1}/{len(pkl_files)}: {pkl_file}\")\n",
    "    \n",
    "    # Cargar datos\n",
    "    X, y, config = load_data(os.path.join(DATA_DIR, pkl_file))\n",
    "    \n",
    "    # Aplicar LabelEncoder a las etiquetas\n",
    "    y_encoded, label_encoder, class_mapping = encode_labels(y)\n",
    "    print(f\"  Clases originales: {label_encoder.classes_}\")\n",
    "    print(f\"  Mapeo de clases: {class_mapping}\")\n",
    "    \n",
    "    # Aplicar oversampling\n",
    "    X_resampled, y_resampled = apply_oversampling(X, y_encoded)\n",
    "    \n",
    "    print(f\"  Datos cargados, etiquetas codificadas y balanceadas. Shape: {X_resampled.shape}\")\n",
    "    print(f\"  Configuración: n-grams={config['ngram_range']}, mode={config['mode']}, svd_components={config['svd_components']}\")\n",
    "    print(f\"  Distribución de clases después de oversampling: {np.bincount(y_resampled)}\")\n",
    "    \n",
    "    # Entrenar y evaluar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"  Entrenando {model_name}...\")\n",
    "        \n",
    "        # Entrenar y evaluar modelo\n",
    "        result = train_and_evaluate(X_resampled, y_resampled, model_name, model, pkl_file, config, class_mapping)\n",
    "        \n",
    "        # Añadir resultados\n",
    "        all_results.append(result)\n",
    "        \n",
    "        print(f\"  {model_name} completado. F1-macro: {result['f1_macro']:.4f}\")\n",
    "\n",
    "# Crear dataframe con todos los resultados\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Ordenar por f1_macro descendente\n",
    "results_df = results_df.sort_values('f1_macro', ascending=False)\n",
    "\n",
    "# Guardar resultados en CSV\n",
    "results_df.to_csv('ml_experiment_results.csv', index=False)\n",
    "\n",
    "# Mostrar los 10 mejores resultados\n",
    "print(\"\\nTop 10 mejores combinaciones (por F1-macro):\")\n",
    "print(results_df.head(10).to_string(index=False))\n",
    "\n",
    "# Mostrar análisis agrupado para tener visión general de rendimiento\n",
    "print(\"\\nRendimiento promedio por tipo de modelo:\")\n",
    "model_perf = results_df.groupby('model')['f1_macro'].mean().sort_values(ascending=False)\n",
    "print(model_perf)\n",
    "\n",
    "print(\"\\nRendimiento promedio por n-gramas:\")\n",
    "ngram_perf = results_df.groupby('ngram_range')['f1_macro'].mean().sort_values(ascending=False)\n",
    "print(ngram_perf)\n",
    "\n",
    "print(\"\\nRendimiento promedio por modo de vectorización:\")\n",
    "mode_perf = results_df.groupby('mode')['f1_macro'].mean().sort_values(ascending=False)\n",
    "print(mode_perf)\n",
    "\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Entorno ESCOM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
